from __future__ import annotations

import os
import tempfile
import logging
from typing import BinaryIO

from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from sqlalchemy import select
from openai import AsyncOpenAI

from core.config import settings
from bot.states import GenStates, CreateStates
from services.queue import enqueue_generation
from db.engine import SessionLocal
from db.models import User

router = Router()
logger = logging.getLogger("voice")

# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
try:
    if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "your_openai_api_key":
        openai_client = None
        logger.warning("OpenAI API key not configured - voice messages disabled")
    else:
        openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        logger.info("OpenAI client initialized successfully")
except Exception as e:
    openai_client = None
    logger.error(f"Failed to initialize OpenAI client: {e}")


async def transcribe_voice_whisper(audio_file: BinaryIO, filename: str = "audio.ogg") -> str:
    """
    ‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenAI Whisper API
    """
    if openai_client is None:
        raise ValueError("OpenAI API not configured")
    
    try:
        transcript = await openai_client.audio.transcriptions.create(
            model=settings.WHISPER_MODEL,
            file=(filename, audio_file, "audio/ogg"),
            language="ru",
            response_format="text"
        )
        
        text = transcript.strip()
        
        logger.info(
            "whisper_transcription_success",
            extra={
                "text_length": len(text),
                "model": settings.WHISPER_MODEL
            }
        )
        
        return text
        
    except Exception as e:
        logger.exception(
            "whisper_transcription_error",
            extra={"error": str(e)}
        )
        raise


@router.message(F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """
    ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ OpenAI Whisper API
    """
    # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ OpenAI
    if openai_client is None:
        await message.answer(
            "‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.\n\n"
            "üí° –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @guard_gpt"
        )
        return
    
    user_id = message.from_user.id
    temp_file_path = None

    cur = await state.get_state()
    data = await state.get_data()
    
    logger.info(
        "voice_message_received",
        extra={
            "user_id": user_id,
            "state": cur,
            "duration": message.voice.duration
        }
    )

    # ‚ùå –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–∞ –≤ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö
    if cur == GenStates.uploading_images.state:
        await message.answer(
            "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ 1‚Äì10 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å.\n"
            "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π."
        )
        return

    if cur in (GenStates.generating.state, CreateStates.generating.state):
        await message.answer("‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è. –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
        return

    processing_msg = await message.answer("üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å —á–µ—Ä–µ–∑ Whisper AI...")

    try:
        file = await message.bot.get_file(message.voice.file_id)
        voice_data = await message.bot.download_file(file.file_path)
        
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_file:
            temp_file.write(voice_data.getvalue())
            temp_file_path = temp_file.name
        
        with open(temp_file_path, "rb") as audio_file:
            text = await transcribe_voice_whisper(audio_file, filename="voice.ogg")
        
        if not text or len(text) < 2:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.\n\n"
                "üí° –°–æ–≤–µ—Ç—ã:\n"
                "‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç—á–µ –∏ –≥—Ä–æ–º—á–µ\n"
                "‚Ä¢ –ó–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ –º–∏–Ω–∏–º—É–º 2 —Å–µ–∫—É–Ω–¥—ã\n"
                "‚Ä¢ –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω–æ–≥–æ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞"
            )
            return
        
        try:
            await processing_msg.edit_text(
                f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>",
                parse_mode="HTML"
            )
        except Exception:
            await message.answer(
                f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>",
                parse_mode="HTML"
            )
            try:
                await processing_msg.delete()
            except Exception:
                pass
        
        async with SessionLocal() as s:
            user = (await s.execute(select(User).where(User.chat_id == user_id))).scalar_one_or_none()
            if not user:
                await message.answer("–ù–∞–∂–º–∏—Ç–µ /start –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")
                return
            
            image_resolution = user.image_resolution
            max_images = user.max_images
        
        # ========== –û–ë–†–ê–ë–û–¢–ö–ê –ü–û –°–û–°–¢–û–Ø–ù–ò–Ø–ú ==========
        
        if cur == GenStates.waiting_prompt.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /gen –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–Ω–∞—á–∞–ª–∞.")
                return
            
            file_ids = [p["file_id"] for p in photos]
            wait_msg = await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            
            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=text,
                base_prompt=text,
                edits=[],
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                image_resolution=image_resolution,
                max_images=max_images,
            )
            
            await enqueue_generation(
                user_id, 
                text, 
                file_ids, 
                image_resolution=image_resolution, 
                max_images=max_images
            )
            return
        
        if cur == GenStates.final_menu.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ù–∞–∂–º–∏—Ç–µ ¬´–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ¬ª.")
                return
            
            base_prompt = (data.get("base_prompt") or data.get("prompt") or "").strip()
            edits = list(data.get("edits") or [])
            edits.append(text)
            
            cumulative_prompt = " ".join([base_prompt] + edits).strip()
            if len(cumulative_prompt) > 4000:
                cumulative_prompt = cumulative_prompt[:4000]
            
            file_ids = [p["file_id"] for p in photos]
            seed = data.get("last_seed")
            
            wait_msg = await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            
            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=cumulative_prompt,
                base_prompt=base_prompt,
                edits=edits,
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                image_resolution=image_resolution,
                max_images=max_images,
            )
            
            await enqueue_generation(
                user_id, 
                cumulative_prompt, 
                file_ids, 
                image_resolution=image_resolution, 
                max_images=max_images, 
                seed=seed
            )
            return
        
        if cur == CreateStates.waiting_prompt.state:
            aspect_ratio = data.get("aspect_ratio")
            
            wait_msg = await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                image_resolution=image_resolution,
                max_images=max_images,
            )
            
            await enqueue_generation(
                user_id, 
                text, 
                [], 
                aspect_ratio=aspect_ratio, 
                image_resolution=image_resolution, 
                max_images=max_images
            )
            return
        
        if cur == CreateStates.final_menu.state:
            last_result_urls = data.get("last_result_urls", [])
            aspect_ratio = data.get("aspect_ratio")
            seed = data.get("last_seed")
            
            wait_msg = await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create_edit",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                image_resolution=image_resolution,
                max_images=max_images,
            )
            
            await enqueue_generation(
                user_id, 
                text, 
                last_result_urls, 
                aspect_ratio=aspect_ratio, 
                image_resolution=image_resolution, 
                max_images=max_images,
                seed=seed
            )
            return
        
        if cur == CreateStates.selecting_aspect_ratio.state:
            aspect_ratio = data.get("aspect_ratio")
            
            wait_msg = await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {max_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                aspect_ratio=aspect_ratio,
                image_resolution=image_resolution,
                max_images=max_images,
            )
            
            await enqueue_generation(
                user_id, 
                text, 
                [], 
                aspect_ratio=aspect_ratio, 
                image_resolution=image_resolution, 
                max_images=max_images
            )
            return
        
        await message.answer(
            "‚ÑπÔ∏è –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n\n"
            "‚Ä¢ <b>/gen</b> –∏–ª–∏ <b>/edit</b> ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ\n"
            "  (–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º —Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç)\n\n"
            "‚Ä¢ <b>/create</b> ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
            "  (—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç —Å—Ä–∞–∑—É)\n\n"
            "‚Ä¢ <b>/set</b> ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞",
            parse_mode="HTML"
        )
    
    except ValueError as e:
        if "not configured" in str(e):
            await processing_msg.edit_text(
                "‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.\n\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @guard_gpt"
            )
    except Exception as e:
        logger.exception(
            "voice_processing_error",
            extra={
                "user_id": user_id,
                "error": str(e)
            }
        )
        
        error_msg = "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è."
        
        error_str = str(e).lower()
        if "insufficient_quota" in error_str or "quota" in error_str:
            error_msg = (
                "‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI API.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @guard_gpt"
            )
        elif "invalid_api_key" in error_str or "authentication" in error_str or "401" in error_str:
            error_msg = (
                "‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É: @guard_gpt"
            )
        elif "timeout" in error_str:
            error_msg = (
                "‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Å–µ—Ä–≤–∏—Å–∞.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
            )
        
        try:
            await processing_msg.edit_text(error_msg)
        except Exception:
            await message.answer(error_msg)
    
    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.remove(temp_file_path)
            except Exception as e:
                logger.warning(
                    "temp_file_cleanup_failed",
                    extra={"path": temp_file_path, "error": str(e)}
                )
